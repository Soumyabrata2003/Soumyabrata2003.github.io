---
layout: post
title:  "ViLP: Knowledge Exploration using Vision, Language and Pose Embeddings for Video Action Recognition"
date:   2023-12-09 17:29:59 +05:30
image: /images/vilp.jpg
categories: research
author: "Soumyabrata Chaudhuri"
authors: "<strong>Soumyabrata Chaudhuri</strong>, <a href=https://scholar.google.com/citations?user=8pffuA4AAAAJ&hl=en>Saumik Bhattacharya</a>"
venue: "ACM ICVGIP 2023 (Oral)"
# website: ""
# venue: "in: Submitted to ACL 2025"
arxiv: "https://arxiv.org/abs/2308.03908"
code: "https://github.com/Soumyabrata2003/ViLP"
# demo: ""

---
ViLP explores cross-modal knowledge from the pre-trained vision-language model (e.g., CLIP) to introduce the novel combination of pose, visual information, and text attributes.